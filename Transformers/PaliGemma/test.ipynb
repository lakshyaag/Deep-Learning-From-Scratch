{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from rich import print\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True\n",
    "    ).raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siglip import SiglipVisionModel\n",
    "from config import SiglipVisionConfig, GemmaLMConfig\n",
    "from gemma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "siglip_config = SiglipVisionConfig()\n",
    "gemma_config = GemmaLMConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((siglip_config.image_size, siglip_config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def reverse_transform(image):\n",
    "    return transforms.ToPILImage()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiglipVisionModel(siglip_config)(transform(sample_image).unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_cache = KVCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GemmaMLP(gemma_config)(torch.randn(1, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_vocab': 256000,\n",
       " 'hidden_size': 768,\n",
       " 'intermediate_size': 3072,\n",
       " 'num_hidden_layers': 12,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_kv_heads': 1,\n",
       " 'd_head': 256,\n",
       " 'max_position_embeddings': 8192,\n",
       " 'rms_norm_eps': 1e-06,\n",
       " 'rope_theta': 10000.0,\n",
       " 'attention_bias': True,\n",
       " 'attention_dropout': 0.0,\n",
       " 'pad_token_id': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0224, -0.0239,  0.0114,  ..., -0.0153, -0.0082,  0.0128],\n",
       "          [-0.0287, -0.0184,  0.0215,  ..., -0.0078, -0.0002,  0.0166],\n",
       "          [-0.0219, -0.0303,  0.0162,  ..., -0.0017, -0.0028,  0.0126],\n",
       "          ...,\n",
       "          [-0.0257, -0.0216,  0.0191,  ..., -0.0126, -0.0051,  0.0129],\n",
       "          [-0.0297, -0.0217,  0.0151,  ..., -0.0111, -0.0045,  0.0105],\n",
       "          [-0.0256, -0.0348,  0.0234,  ..., -0.0154, -0.0087,  0.0192]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[[0.0011, 0.0011, 0.0008,  ..., 0.0014, 0.0008, 0.0009],\n",
       "           [0.0011, 0.0007, 0.0008,  ..., 0.0010, 0.0007, 0.0010],\n",
       "           [0.0011, 0.0012, 0.0006,  ..., 0.0009, 0.0007, 0.0012],\n",
       "           ...,\n",
       "           [0.0017, 0.0011, 0.0012,  ..., 0.0012, 0.0005, 0.0012],\n",
       "           [0.0009, 0.0005, 0.0006,  ..., 0.0008, 0.0012, 0.0008],\n",
       "           [0.0011, 0.0011, 0.0005,  ..., 0.0012, 0.0009, 0.0006]],\n",
       " \n",
       "          [[0.0006, 0.0008, 0.0012,  ..., 0.0009, 0.0009, 0.0013],\n",
       "           [0.0005, 0.0012, 0.0009,  ..., 0.0006, 0.0005, 0.0006],\n",
       "           [0.0010, 0.0009, 0.0015,  ..., 0.0008, 0.0007, 0.0011],\n",
       "           ...,\n",
       "           [0.0006, 0.0010, 0.0011,  ..., 0.0013, 0.0005, 0.0006],\n",
       "           [0.0014, 0.0007, 0.0013,  ..., 0.0008, 0.0006, 0.0008],\n",
       "           [0.0017, 0.0011, 0.0014,  ..., 0.0009, 0.0024, 0.0008]],\n",
       " \n",
       "          [[0.0008, 0.0007, 0.0012,  ..., 0.0007, 0.0015, 0.0008],\n",
       "           [0.0011, 0.0010, 0.0011,  ..., 0.0007, 0.0004, 0.0010],\n",
       "           [0.0009, 0.0012, 0.0007,  ..., 0.0013, 0.0006, 0.0008],\n",
       "           ...,\n",
       "           [0.0013, 0.0006, 0.0007,  ..., 0.0019, 0.0012, 0.0012],\n",
       "           [0.0007, 0.0009, 0.0008,  ..., 0.0008, 0.0008, 0.0013],\n",
       "           [0.0006, 0.0005, 0.0010,  ..., 0.0006, 0.0012, 0.0008]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0006, 0.0009, 0.0010,  ..., 0.0013, 0.0014, 0.0012],\n",
       "           [0.0010, 0.0005, 0.0009,  ..., 0.0007, 0.0014, 0.0008],\n",
       "           [0.0009, 0.0008, 0.0009,  ..., 0.0008, 0.0015, 0.0012],\n",
       "           ...,\n",
       "           [0.0012, 0.0009, 0.0008,  ..., 0.0023, 0.0015, 0.0015],\n",
       "           [0.0008, 0.0008, 0.0010,  ..., 0.0007, 0.0011, 0.0012],\n",
       "           [0.0005, 0.0009, 0.0007,  ..., 0.0014, 0.0004, 0.0013]],\n",
       " \n",
       "          [[0.0010, 0.0008, 0.0015,  ..., 0.0010, 0.0013, 0.0011],\n",
       "           [0.0005, 0.0010, 0.0011,  ..., 0.0008, 0.0009, 0.0010],\n",
       "           [0.0006, 0.0007, 0.0009,  ..., 0.0009, 0.0009, 0.0014],\n",
       "           ...,\n",
       "           [0.0014, 0.0010, 0.0009,  ..., 0.0007, 0.0010, 0.0007],\n",
       "           [0.0005, 0.0012, 0.0011,  ..., 0.0007, 0.0006, 0.0011],\n",
       "           [0.0014, 0.0007, 0.0012,  ..., 0.0012, 0.0011, 0.0006]],\n",
       " \n",
       "          [[0.0007, 0.0014, 0.0008,  ..., 0.0011, 0.0009, 0.0011],\n",
       "           [0.0007, 0.0010, 0.0012,  ..., 0.0007, 0.0009, 0.0012],\n",
       "           [0.0009, 0.0008, 0.0008,  ..., 0.0013, 0.0013, 0.0018],\n",
       "           ...,\n",
       "           [0.0006, 0.0009, 0.0007,  ..., 0.0009, 0.0011, 0.0012],\n",
       "           [0.0007, 0.0011, 0.0007,  ..., 0.0012, 0.0008, 0.0007],\n",
       "           [0.0011, 0.0013, 0.0012,  ..., 0.0008, 0.0009, 0.0008]]]],\n",
       "        grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GemmaAttention(gemma_config, 2)(\n",
    "    x=torch.randn(1, 1024, 768),\n",
    "    position_ids=torch.arange(0, 1024).unsqueeze(0),\n",
    "    attention_mask=torch.zeros(1, 1024, 1024).to(torch.bool),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GemmaDecoderLayer(gemma_config, 1)(\n",
    "    x=torch.randn(1, 1024, 768),\n",
    "    position_ids=torch.arange(0, 1024).unsqueeze(0),\n",
    "    attention_mask=torch.zeros(1, 1024, 1024).to(torch.bool),\n",
    ").shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0875,  0.4269,  0.5383,  ..., -1.0789,  0.5787,  0.4501],\n",
       "         [ 0.1616, -0.4688,  0.6504,  ...,  3.1006,  0.1916, -0.8189],\n",
       "         [-1.2053,  0.4819,  0.5114,  ...,  0.1484,  0.2750,  0.3186],\n",
       "         ...,\n",
       "         [-1.1503, -0.8338,  1.0890,  ..., -0.3209, -1.0701,  1.7089],\n",
       "         [-1.0619, -0.8395, -1.0407,  ..., -0.9515, -0.2752,  0.6259],\n",
       "         [ 0.3239,  0.4989, -0.3559,  ...,  1.7687, -1.2566,  0.8716]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GemmaModel(gemma_config)(\n",
    "    input_embd=torch.randn(1, 1024, 768),\n",
    "    position_ids=torch.arange(0, 1024).unsqueeze(0),\n",
    "    attention_mask=torch.zeros(1, 1024, 1024).to(torch.bool),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_config.num_hidden_layers = 2\n",
    "GemmaLM(gemma_config)(\n",
    "    input_embd=torch.randn(1, 1024, 768),\n",
    "    position_ids=torch.arange(0, 1024).unsqueeze(0),\n",
    "    attention_mask=torch.zeros(1, 1024, 1024).to(torch.bool),\n",
    "    kv_cache=kv_cache,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
